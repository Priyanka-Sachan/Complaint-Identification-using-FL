{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Code_with_FL_IID",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Priyanka-Sachan/Complaint-Identification-using-FL/blob/master/Code_with_FL_IID.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IoOlZk6KaB-"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tJi_7GgKaCC"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install sentencepiece\n",
        "!pip install datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DpBfDfgKaCD"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from fastai.text import *\n",
        "from google.colab import files\n",
        "\n",
        "import transformers\n",
        "transformers.logging.set_verbosity_error()\n",
        "from transformers import AdamW\n",
        "from transformers import XLNetModel, XLNetTokenizer, XLNetForSequenceClassification\n",
        "from transformers import get_scheduler\n",
        "from datasets import load_metric\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "import math\n",
        "import pandas as pd\n",
        "import io\n",
        "import numpy as np\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPK_sAsdkw-S"
      },
      "source": [
        "# For Reproducibility\n",
        "SEED=9\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92xAoCTmKaCE"
      },
      "source": [
        "class EarlyStopping:\n",
        "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
        "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): How long to wait after last time validation loss improved.\n",
        "                            Default: 7\n",
        "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
        "                            Default: False\n",
        "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
        "                            Default: 0\n",
        "            path (str): Path for the checkpoint to be saved to.\n",
        "                            Default: 'checkpoint.pt'\n",
        "            trace_func (function): trace print function.\n",
        "                            Default: print            \n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "        self.path = path\n",
        "        self.trace_func = trace_func\n",
        "    def __call__(self, val_loss, model):\n",
        "\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        '''Saves model when validation loss decrease.'''\n",
        "        if self.verbose:\n",
        "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), self.path)\n",
        "        self.val_loss_min = val_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORMJtxpPKaCG"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "torch.cuda.get_device_name(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOgS5CvC4ODG"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6M7_IyeSp0d"
      },
      "source": [
        "def create_dataloader(input_ids,masks,labels):\n",
        "\n",
        "  input_ids=torch.tensor(input_ids)\n",
        "  masks=torch.tensor(masks)\n",
        "  labels=torch.tensor(labels)\n",
        "\n",
        "  data = TensorDataset(input_ids,masks,labels)\n",
        "  sampler = SequentialSampler(data)\n",
        "  dataloader = DataLoader(data, sampler=sampler, batch_size=32) \n",
        "\n",
        "  return dataloader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZnDThgZcvoV"
      },
      "source": [
        "# To train main model intially with amazon reviews\n",
        "def train_main_model(model,optimizer):\n",
        "\n",
        "  path = untar_data(URLs.AMAZON_REVIEWS, dest = \"Data\")\n",
        "  df = pd.read_csv(path/'train.csv', header=None, names=['rating', 'title', 'review'],  nrows=30000)\n",
        "\n",
        "  label=[]\n",
        "  for rating in df.rating.values:\n",
        "    if(rating>2):\n",
        "      label.append(0)\n",
        "    else:\n",
        "      label.append(1)\n",
        "  df['label']=label\n",
        "\n",
        "  sentences=df.review.values\n",
        "  tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased', do_lower_case=True)\n",
        "  MAX_LEN=49\n",
        "  tokens= [tokenizer(sentence, padding='max_length',truncation=\"only_first\", max_length=MAX_LEN) for sentence in sentences]\n",
        "\n",
        "  input_ids=np.asarray([np.asarray(token['input_ids']) for token in tokens])\n",
        "  attention_masks=np.asarray([np.asarray(token['attention_mask']) for token in tokens])\n",
        "  labels=df.label.values\n",
        " \n",
        "  train_inputs, valid_inputs, train_masks, valid_masks,train_labels, valid_labels = train_test_split(input_ids,attention_masks, labels,random_state=42, test_size=0.2)\n",
        "\n",
        "  train_dataloader=create_dataloader(train_inputs,train_masks,train_labels)\n",
        "  validation_dataloader=create_dataloader(valid_inputs,valid_masks,valid_labels)\n",
        "\n",
        "  train_accuracy,train_loss,valid_accuracy,valid_loss=train_and_validate_model(model,optimizer,train_dataloader,validation_dataloader)\n",
        " \n",
        "  torch.save(model.state_dict(), F\"/content/gdrive/My Drive/Innovation_Lab/main_model.pt\" )\n",
        "  torch.save(optimizer.state_dict(), F\"/content/gdrive/My Drive/Innovation_Lab/main_optimizer.pt\" )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqXflY0kj2fM"
      },
      "source": [
        "# Extract features from complaints data\n",
        "def get_features():\n",
        "\n",
        "  uploaded = files.upload()\n",
        "\n",
        "  df = pd.read_csv(\"complaints-data.csv\", header=None, names=['id', 'tweet', 'y', 'industry'])\n",
        "\n",
        "  sentences=df.tweet.values\n",
        "  tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased', do_lower_case=True)\n",
        "  MAX_LEN=49\n",
        "  tokens= [tokenizer(sentence, padding='max_length',truncation=\"only_first\", max_length=MAX_LEN) for sentence in sentences]\n",
        "\n",
        "  input_ids=np.asarray([np.asarray(token['input_ids']) for token in tokens])\n",
        "  attention_masks=np.asarray([np.asarray(token['attention_mask']) for token in tokens])\n",
        "  labels=df.y.values\n",
        "\n",
        "  return input_ids,attention_masks,labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3H9mTZ96HDWP"
      },
      "source": [
        "# Shuffling and dividing the data into 2 parts based on label\n",
        "def split_and_shuffle_labels(labels, seed):\n",
        "\n",
        "    labels=pd.DataFrame(labels,columns=[\"labels\"])\n",
        "    labels[\"i\"]=np.arange(len(labels))\n",
        "    label_dict = dict()\n",
        "\n",
        "    for i in range(2):\n",
        "        var_name=\"label\" + str(i)\n",
        "        label_info=labels[labels[\"labels\"]==i]\n",
        "        np.random.seed(seed)\n",
        "        label_info=np.random.permutation(label_info)\n",
        "        label_info=pd.DataFrame(label_info, columns=[\"labels\",\"i\"])\n",
        "        label_dict.update({var_name: label_info })\n",
        "        \n",
        "    return label_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCuJ5XeWHFdO"
      },
      "source": [
        "# Divides the indexes in each node with an proportionate number of each label\n",
        "def get_iid_subsamples_indices(label_dict, number_of_samples):\n",
        "\n",
        "    sample_dict= dict()\n",
        "    for i in range(number_of_samples):\n",
        "        sample_name=\"sample\"+str(i)\n",
        "        samples=pd.DataFrame()\n",
        "        \n",
        "        for j in range(2):\n",
        "            label_name=str(\"label\")+str(j)\n",
        "            batch_size=int(math.floor(label_dict[label_name].shape[0]/number_of_samples))\n",
        "            label_sample=label_dict[label_name][i*batch_size:(i+1)*batch_size]\n",
        "            samples=pd.concat([samples,label_sample], axis=0)\n",
        "        samples.reset_index(drop=True, inplace=True)    \n",
        "        sample_dict.update({sample_name: samples})\n",
        "\n",
        "    return sample_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnayZ83EHIOj"
      },
      "source": [
        "# Distributes input ids, attention masks and labels to nodes in dictionary\n",
        "def create_iid_subsamples(sample_dict, input_ids,attention_masks,labels,group):\n",
        "  \n",
        "    input_ids_dict= dict()\n",
        "    attention_masks_dict=dict()\n",
        "    labels_dict= dict()\n",
        "    \n",
        "    for i in range(number_of_samples):  \n",
        "\n",
        "        input_id_name= group+\"_input_id\"+str(i)\n",
        "        attention_mask_name=group+\"_attention_mask\"+str(i)\n",
        "        label_name= group+\"_label\"+str(i)\n",
        "        sample_name=\"sample\"+str(i)\n",
        "        \n",
        "        indices=np.sort(np.array(sample_dict[sample_name][\"i\"]))\n",
        "        \n",
        "        input_ids_info= input_ids[indices,:]\n",
        "        input_ids_dict.update({input_id_name : input_ids_info})\n",
        "\n",
        "        attention_masks_info= attention_masks[indices,:]\n",
        "        attention_masks_dict.update({attention_mask_name : attention_masks_info})\n",
        "        \n",
        "        labels_info= labels[indices]\n",
        "        labels_dict.update({label_name : labels_info})\n",
        "        \n",
        "    return input_ids_dict,attention_masks_dict, labels_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQgXPRmKKaCS"
      },
      "source": [
        "# To train and validate local models\n",
        "def train_and_validate_model(model,optimizer,train_dataloader,validation_dataloader): \n",
        " \n",
        "    model.cuda()\n",
        "\n",
        "    num_epochs = 4\n",
        "    num_training_steps = num_epochs * len(train_dataloader)\n",
        "    lr_scheduler = get_scheduler(\n",
        "        \"linear\",\n",
        "        optimizer=optimizer,\n",
        "        num_warmup_steps=0,\n",
        "        num_training_steps=num_training_steps\n",
        "    )\n",
        "    early_stopping = EarlyStopping(patience=3, verbose=False)\n",
        " \n",
        "    train_accuracy_metric=load_metric(\"accuracy\")\n",
        "    valid_accuracy_metric=load_metric(\"accuracy\")\n",
        " \n",
        "    train_loss,valid_loss=0,0\n",
        "    pr_train_loss,pr_valid_loss=0,0\n",
        " \n",
        "    progress_bar = tqdm(range(num_training_steps))\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "      train_losses = []\n",
        "      valid_losses = []\n",
        " \n",
        "      model.train()\n",
        "      for batch in train_dataloader:\n",
        "          batch = tuple(t.to(device) for t in batch)\n",
        "          b_input_ids, b_input_mask, b_labels = batch\n",
        "          b_input_ids.cuda()\n",
        "          b_input_mask.cuda()\n",
        "          b_labels.cuda()\n",
        "          outputs = model(input_ids=b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
        "          loss = outputs.loss\n",
        "          logits = outputs.logits\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          lr_scheduler.step()\n",
        " \n",
        "          train_losses.append(loss.item())\n",
        "          predictions = torch.argmax(logits, dim=-1)\n",
        "          train_accuracy_metric.add_batch(predictions=predictions,references=b_labels)\n",
        " \n",
        "          optimizer.zero_grad()\n",
        "          progress_bar.update(1)\n",
        " \n",
        "      model.eval()\n",
        "      for batch in validation_dataloader:\n",
        "          batch = tuple(t.to(device) for t in batch)\n",
        "          b_input_ids, b_input_mask, b_labels = batch\n",
        "          b_input_ids.cuda()\n",
        "          b_input_mask.cuda()\n",
        "          b_labels.cuda()\n",
        "          with torch.no_grad():\n",
        "              outputs = model(input_ids=b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
        "          loss = outputs.loss\n",
        "          logits = outputs.logits\n",
        " \n",
        "          valid_losses.append(loss.item())\n",
        "          predictions = torch.argmax(logits, dim=-1)\n",
        "          valid_accuracy_metric.add_batch(predictions=predictions,references=b_labels)\n",
        " \n",
        "      pr_train_loss=train_loss\n",
        "      train_loss = np.average(train_losses)\n",
        "      pr_valid_loss=valid_loss\n",
        "      valid_loss = np.average(valid_losses)\n",
        " \n",
        "      early_stopping(valid_loss, model)\n",
        "          \n",
        "      if early_stopping.early_stop:\n",
        "          print(\"Early stopping\")\n",
        "          valid_loss=pr_valid_loss\n",
        "          train_loss=pr_train_loss\n",
        "          break\n",
        "\n",
        "      train_accuracy=train_accuracy_metric.compute()['accuracy']\n",
        "      valid_accuracy=valid_accuracy_metric.compute()['accuracy']\n",
        "\n",
        "      print(\"EPOCH: {}\".format(epoch+1),\n",
        "            \"| Train accuracy: {:7.5f}\".format(train_accuracy),\n",
        "            \"| Train loss: {:7.5f}\".format(train_loss),\n",
        "            \"| Validation accuracy: {:7.5f}\".format(valid_accuracy),\n",
        "            \"| Validation loss: {:7.5f}\".format(valid_loss))\n",
        "\n",
        "    model.cpu()\n",
        " \n",
        "    return train_accuracy,train_loss,valid_accuracy,valid_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZZTSVXHjlKX"
      },
      "source": [
        "# Evaluate models\n",
        "def test_model(model,test_dataloader):\n",
        "\n",
        "    model.cuda()\n",
        "\n",
        "    test_losses=[]\n",
        "    test_accuracy_metric=load_metric(\"accuracy\")\n",
        "    test_precision_metric=load_metric(\"precision\")\n",
        "    test_recall_metric=load_metric(\"recall\")\n",
        "    test_f1_metric=load_metric(\"f1\")\n",
        "    \n",
        "    model.eval()\n",
        "    for batch in test_dataloader:\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        with torch.no_grad():\n",
        "            outputs = model(input_ids=b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
        "        loss = outputs.loss\n",
        "        logits = outputs.logits\n",
        " \n",
        "        test_losses.append(loss.item())\n",
        "        predictions = torch.argmax(logits, dim=-1)\n",
        "        test_accuracy_metric.add_batch(predictions=predictions,references=b_labels)\n",
        "        test_precision_metric.add_batch(predictions=predictions,references=b_labels)\n",
        "        test_recall_metric.add_batch(predictions=predictions,references=b_labels)\n",
        "        test_f1_metric.add_batch(predictions=predictions,references=b_labels)\n",
        " \n",
        "    test_loss = np.average(test_losses)\n",
        "    test_accuracy=test_accuracy_metric.compute()['accuracy']\n",
        "    test_precision=test_precision_metric.compute()['precision']\n",
        "    test_recall=test_recall_metric.compute()['recall']\n",
        "    test_f1=test_f1_metric.compute()['f1']\n",
        "\n",
        "    model.cpu()\n",
        " \n",
        "    return test_accuracy,test_loss,test_precision,test_recall,test_f1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9BbfC30HU9J"
      },
      "source": [
        "# Creates a model and optimizer function for each node\n",
        "def create_model_optimizer_dict(number_of_samples):\n",
        "\n",
        "    model_dict = dict()\n",
        "    optimizer_dict= dict()\n",
        "    \n",
        "    for i in range(number_of_samples):\n",
        "\n",
        "        model_name=\"model\"+str(i)\n",
        "        model_info=XLNetForSequenceClassification.from_pretrained(pretrained_model_name_or_path=\"xlnet-base-cased\", num_labels=2)\n",
        "        model_dict.update({model_name : model_info })\n",
        "\n",
        "        optimizer_name=\"optimizer\"+str(i)\n",
        "        optimizer_info = AdamW(model_dict[model_name].parameters(),lr=2e-5)\n",
        "        optimizer_dict.update({optimizer_name : optimizer_info })\n",
        "        \n",
        "    return model_dict, optimizer_dict "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdq_IfeJH6uE"
      },
      "source": [
        "# Trains individual local models in nodes\n",
        "def start_train_end_node_process(number_of_samples):\n",
        "  \n",
        "    for i in range (number_of_samples): \n",
        "\n",
        "        train_dataloader=create_dataloader(train_input_ids_dict[name_of_x_train_sets[i]],\n",
        "                                           train_attention_masks_dict[name_of_x_masks_train_sets[i]],\n",
        "                                           train_labels_dict[name_of_y_train_sets[i]])\n",
        "        validation_dataloader=create_dataloader(valid_input_ids_dict[name_of_x_valid_sets[i]],\n",
        "                                                valid_attention_masks_dict[name_of_x_masks_valid_sets[i]],\n",
        "                                                valid_labels_dict[name_of_y_valid_sets[i]])\n",
        "\n",
        "        model=model_dict[name_of_models[i]]\n",
        "        optimizer=optimizer_dict[name_of_optimizers[i]]\n",
        "\n",
        "        train_accuracy,train_loss,valid_accuracy,valid_loss=train_and_validate_model(model,optimizer,train_dataloader,validation_dataloader)\n",
        "    \n",
        "        print(\"CLIENT: {}\".format(i+1) + \n",
        "              \" | Train accuracy: {:7.5f}\".format(train_accuracy)+ \n",
        "              \" | Train loss: {:7.5f}\".format(train_loss) +\n",
        "              \" | Validation accuracy: {:7.5f}\".format(valid_accuracy)+\n",
        "              \" | Validation loss: {:7.5f}\".format(valid_loss))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m370kqzUJMXe"
      },
      "source": [
        "# Sends the averaged weights of individual nodes to the main model and sets them as the new weights of the main model\n",
        "def get_averaged_weights_and_update_main_model(model_dict, number_of_samples):\n",
        "\n",
        "    with torch.no_grad():\n",
        "        main_model.cuda()\n",
        "\n",
        "        for i in range(number_of_samples):\n",
        "            model_dict[\"model\"+str(i)].cuda()\n",
        "\n",
        "            for client_parameters,main_model_parameters in zip(model_dict[\"model\"+str(i)].parameters(),main_model.parameters()):\n",
        "\n",
        "                if i==0:\n",
        "                    main_model_parameters.data=client_parameters.data.clone().detach()\n",
        "                    main_model_parameters.data/=number_of_samples\n",
        "                else:\n",
        "                    main_model_parameters.data+=client_parameters.data/number_of_samples\n",
        "\n",
        "            model_dict[\"model\"+str(i)].cpu()\n",
        "\n",
        "        main_model.cpu()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ud2B7v5sJj5H"
      },
      "source": [
        "# Compares the accuracy of the main model and the local model running on each node\n",
        "def compare_local_and_merged_model_performance(number_of_samples):\n",
        "\n",
        "    test_dataloader=create_dataloader(test_inputs, test_masks, test_labels)\n",
        "\n",
        "    accuracy_table=pd.DataFrame(data=np.zeros((number_of_samples+1,5)), columns=[\"Model\", \"Accuracy\", \"Precision\",\"Recall\",\"F1\"])\n",
        "    \n",
        "    accuracy,loss,precision,recall,f1 = test_model(main_model, test_dataloader)\n",
        "    \n",
        "    accuracy_table.loc[0, \"Model\"]=\"Main Model\"\n",
        "    accuracy_table.loc[0, \"Accuracy\"] = accuracy\n",
        "    accuracy_table.loc[0, \"Precision\"] = precision\n",
        "    accuracy_table.loc[0, \"Recall\"] = recall\n",
        "    accuracy_table.loc[0, \"F1\"] = f1\n",
        "\n",
        "    for i in range (number_of_samples):\n",
        "\n",
        "        model=model_dict[name_of_models[i]]\n",
        "        optimizer=optimizer_dict[name_of_optimizers[i]]\n",
        "\n",
        "        accuracy,loss,precision,recall,f1 = test_model(model, test_dataloader)\n",
        "    \n",
        "        accuracy_table.loc[i+1, \"Model\"]=\"Client \"+str(i)\n",
        "        accuracy_table.loc[i+1, \"Accuracy\"] = accuracy\n",
        "        accuracy_table.loc[i+1, \"Precision\"] = precision\n",
        "        accuracy_table.loc[i+1, \"Recall\"] = recall\n",
        "        accuracy_table.loc[i+1, \"F1\"] = f1\n",
        "\n",
        "    return accuracy_table"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBu6y9m7KKLB"
      },
      "source": [
        "# To send the merged parameters of the main model to local models\n",
        "def send_main_model_to_nodes_and_update_model_dict(main_model, model_dict, number_of_samples):\n",
        "\n",
        "    with torch.no_grad():\n",
        "        main_model.cuda()\n",
        "\n",
        "        for i in range(number_of_samples):\n",
        "            model_dict[\"model\"+str(i)].cuda()\n",
        "\n",
        "            for client_parameters,main_model_parameters in zip(model_dict[\"model\"+str(i)].parameters(),main_model.parameters()):\n",
        "                client_parameters.data=main_model_parameters.data.clone().detach()\n",
        "\n",
        "            model_dict[\"model\"+str(i)].cpu()\n",
        "            \n",
        "        main_model.cpu()  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0W4EzfOXhkK"
      },
      "source": [
        "###EXPERIMENTATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fr6HabMDHNdS"
      },
      "source": [
        "# Creating the main model\n",
        "# Load XLNEtForSequenceClassification, the pretrained XLNet model with a single linear classification layer on top. \n",
        "main_model = XLNetForSequenceClassification.from_pretrained(\"xlnet-base-cased\", num_labels=2)\n",
        "main_optimizer = AdamW(main_model.parameters(),lr=2e-5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sONf5w-PgwKk"
      },
      "source": [
        "# Initially, training model for once.\n",
        "# train_main_model(main_model,main_optimizer)\n",
        "# Or loading weights from drive\n",
        "main_model.load_state_dict(torch.load( F\"/content/gdrive/My Drive/Innovation_Lab/main_model.pt\"))\n",
        "main_optimizer.load_state_dict(torch.load( F\"/content/gdrive/My Drive/Innovation_Lab/main_optimizer.pt\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7qIHivqkRm-"
      },
      "source": [
        "# Getting input ids, attention masks and labels from complaints\n",
        "input_ids,attention_masks,labels=get_features()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RaVR16b5R6gi"
      },
      "source": [
        "number_of_samples=4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBbCtpy0LWXB"
      },
      "source": [
        "# Use train_test_split to split our data into train and validation sets for training\n",
        "\n",
        "train_inputs, val_test_inputs, train_masks, val_test_masks,train_labels, val_test_labels = train_test_split(input_ids,attention_masks, labels,random_state=42, test_size=0.2)\n",
        "validation_inputs, test_inputs,validation_masks, test_masks, validation_labels, test_labels = train_test_split(val_test_inputs,val_test_masks, val_test_labels,random_state=42, test_size=0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eH75iViLLXx0"
      },
      "source": [
        "# Creating clients with train and validation dataset\n",
        "\n",
        "train_id_dict=split_and_shuffle_labels(train_labels, seed=1) \n",
        "train_sample_dict=get_iid_subsamples_indices(label_dict=train_id_dict, number_of_samples=number_of_samples)\n",
        "train_input_ids_dict,train_attention_masks_dict, train_labels_dict = create_iid_subsamples(train_sample_dict, train_inputs,train_masks,train_labels,\"train\")\n",
        "\n",
        "valid_id_dict = split_and_shuffle_labels(validation_labels, seed=1) \n",
        "valid_sample_dict = get_iid_subsamples_indices(valid_id_dict, number_of_samples=number_of_samples)\n",
        "valid_input_ids_dict,valid_attention_masks_dict, valid_labels_dict = create_iid_subsamples(valid_sample_dict, validation_inputs,validation_masks,validation_labels,\"valid\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwAi3XwpLjgt"
      },
      "source": [
        "# Models and optimizers functions in nodes are defined\n",
        "model_dict, optimizer_dict = create_model_optimizer_dict(number_of_samples)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVejrglhLquE"
      },
      "source": [
        "# Keys of dicts are being made iterable\n",
        "\n",
        "name_of_x_train_sets=list(train_input_ids_dict.keys())\n",
        "name_of_x_masks_train_sets=list(train_attention_masks_dict.keys())\n",
        "name_of_y_train_sets=list(train_labels_dict.keys())\n",
        "\n",
        "name_of_x_valid_sets=list(valid_input_ids_dict.keys())\n",
        "name_of_x_masks_valid_sets=list(valid_attention_masks_dict.keys())\n",
        "name_of_y_valid_sets=list(valid_labels_dict.keys())\n",
        "\n",
        "name_of_models=list(model_dict.keys())\n",
        "name_of_optimizers=list(optimizer_dict.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tj8d910ujqqE"
      },
      "source": [
        "# Updating client models\n",
        "send_main_model_to_nodes_and_update_model_dict(main_model, model_dict, number_of_samples)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulrFOMs2LuCJ"
      },
      "source": [
        "# Models in the nodes are trained\n",
        "start_train_end_node_process(number_of_samples)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RoW2OFVnR_Z"
      },
      "source": [
        "# Compares the accuracy of the main model and the local model running on each node\n",
        "compare_local_and_merged_model_performance(number_of_samples)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ho26CEdhL1Ot"
      },
      "source": [
        "# Update all client models to the federated average\n",
        "get_averaged_weights_and_update_main_model(model_dict, number_of_samples)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyvdK7jUL7CJ"
      },
      "source": [
        "# Compares the accuracy of the main model and the local model running on each node\n",
        "compare_local_and_merged_model_performance(number_of_samples)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WS6t_zkBL9g1"
      },
      "source": [
        "# Updating client models\n",
        "send_main_model_to_nodes_and_update_model_dict(main_model, model_dict, number_of_samples)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_nvXznzvlfJ"
      },
      "source": [
        "##Result\n",
        "```\n",
        "\t  Model                   Accuracy\tPrecision\t  Recall\tF1\n",
        "1\tMain Model (before FL)   0.759420\t0.646739\t0.868613\t0.741433\n",
        "2    Main Model (after FL)    0.855072\t0.804196\t0.839416\t0.821429\n",
        "3\tClient 0\t             0.843478\t0.771242\t0.861314\t0.813793\n",
        "4\tClient 1\t             0.872464\t0.825175\t0.861314\t0.842857\n",
        "5\tClient 2\t             0.843478\t0.790210\t0.824818\t0.807143\n",
        "6\tClient 3\t             0.872464\t0.849624\t0.824818\t0.837037\n",
        "```"
      ]
    }
  ]
}