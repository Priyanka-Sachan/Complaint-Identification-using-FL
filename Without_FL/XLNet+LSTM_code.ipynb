{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "XLNet+LSTM_code",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Priyanka-Sachan/Complaint-Identification-using-FL/blob/master/Without_FL/XLNet%2BLSTM_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEfSbAA4QHas"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NmMdkZO8R6q"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install sentencepiece\n",
        "!pip install datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ok002ceNB8E7"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "import transformers\n",
        "transformers.logging.set_verbosity_error()\n",
        "from transformers import AdamW\n",
        "from transformers import XLNetModel, XLNetTokenizer\n",
        "from transformers import get_scheduler\n",
        "from datasets import load_metric\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "import pandas as pd\n",
        "import io\n",
        "import numpy as np\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOfdneHNqWku"
      },
      "source": [
        "# For Reproducibility\n",
        "SEED=9\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlJ02Pvwf55f"
      },
      "source": [
        "class EarlyStopping:\n",
        "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
        "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): How long to wait after last time validation loss improved.\n",
        "                            Default: 7\n",
        "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
        "                            Default: False\n",
        "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
        "                            Default: 0\n",
        "            path (str): Path for the checkpoint to be saved to.\n",
        "                            Default: 'checkpoint.pt'\n",
        "            trace_func (function): trace print function.\n",
        "                            Default: print            \n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "        self.path = path\n",
        "        self.trace_func = trace_func\n",
        "    def __call__(self, val_loss, model):\n",
        "\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        '''Saves model when validation loss decrease.'''\n",
        "        if self.verbose:\n",
        "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), self.path)\n",
        "        self.val_loss_min = val_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYsV4H8fCpZ-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "7077d904-5a60-4346-fc79-1b99089a90af"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "torch.cuda.get_device_name(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Tesla K80'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmrGKF01_7Z_"
      },
      "source": [
        "##Reading and Pre-processing dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UkeC7SG2krJ"
      },
      "source": [
        "# Load the .csv file.\n",
        "data = pd.read_csv(\"complaints-data.csv\", header=None, names=['id', 'tweet', 'y', 'industry'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcEAbCxiZOiT"
      },
      "source": [
        "# Tokenize sentences\n",
        "sentences=data.tweet.values\n",
        "tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased', do_lower_case=True)\n",
        "MAX_LEN=49\n",
        "tokens= [tokenizer(sentence,add_special_tokens=False, padding='max_length',truncation=\"only_first\", max_length=MAX_LEN) for sentence in sentences]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeKuiqNao777"
      },
      "source": [
        "# Get input ids, attention masks and labels.\n",
        "input_ids=np.asarray([np.asarray(token['input_ids']) for token in tokens])\n",
        "attention_masks=np.asarray([np.asarray(token['attention_mask']) for token in tokens])\n",
        "labels=data.y.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_aXFmBgAAeU"
      },
      "source": [
        "##Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yIbdnOg0wd0"
      },
      "source": [
        "# Getting xlnet model for word embedding\n",
        "xlnet=XLNetModel.from_pretrained('xlnet-base-cased')\n",
        "# Freeze all the parameters\n",
        "for param in xlnet.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzlaaNOV0UvV"
      },
      "source": [
        "class LSTM(nn.Module):\n",
        "    \n",
        "    #define all the layers used in model\n",
        "    def __init__(self,xlnet,input_size=768,hidden_size=128,num_layers=3,bidirectional=True,dropout=0.1):\n",
        "        \n",
        "        #Constructor\n",
        "        super(LSTM,self).__init__()          \n",
        "        \n",
        "        #embedding layer\n",
        "        self.xlnet = xlnet\n",
        "        \n",
        "        #lstm layer\n",
        "        self.lstm = nn.LSTM(input_size=input_size, \n",
        "                            hidden_size=hidden_size, \n",
        "                           num_layers=num_layers, \n",
        "                           bidirectional=bidirectional, \n",
        "                           dropout=dropout,\n",
        "                           batch_first=True)\n",
        "        \n",
        "        #dropout\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        \n",
        "        #dense layer\n",
        "        self.fc = nn.Linear(hidden_size * 2, 2)\n",
        "        \n",
        "    def forward(self, ids,masks):\n",
        "        \n",
        "        #text = [batch size,sent_length]\n",
        "        embedded = self.xlnet(input_ids=ids,attention_mask=masks)[0]\n",
        "        #embedded = [batch size, sent_len, emb dim]\n",
        "        \n",
        "        packed_output, (hidden, cell) = self.lstm(embedded)\n",
        "        #hidden = [batch size, num layers * num directions,hid dim]\n",
        "        #cell = [batch size, num layers * num directions,hid dim]\n",
        "        \n",
        "        #concat the final forward and backward hidden state\n",
        "        hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)\n",
        "                \n",
        "        #hidden = [batch size, hid dim * num directions]\n",
        "        logits=self.fc(self.dropout(hidden))\n",
        "        \n",
        "        return logits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQ6ryQ8cADVc"
      },
      "source": [
        "##Training and Testing functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SX47HxYb98ka"
      },
      "source": [
        "# Function to  create dataloader\n",
        "def create_dataloader(input_ids,masks,labels):\n",
        "\n",
        "  input_ids=torch.tensor(input_ids)\n",
        "  masks=torch.tensor(masks)\n",
        "  labels=torch.tensor(labels)\n",
        "\n",
        "  data = TensorDataset(input_ids,masks,labels)\n",
        "  sampler = SequentialSampler(data)\n",
        "  dataloader = DataLoader(data, sampler=sampler, batch_size=32) \n",
        "\n",
        "  return dataloader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sv029I3s5pN3"
      },
      "source": [
        "#Function to train and validate a model\n",
        "def train_and_validate_model(learning_rate,train_dataloader,validation_dataloader): \n",
        " \n",
        "    model = LSTM(xlnet)\n",
        "    model.cuda()\n",
        "\n",
        "    optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
        "    criterion=nn.CrossEntropyLoss()\n",
        "\n",
        "    num_epochs = 4\n",
        "    num_training_steps = num_epochs * len(train_dataloader)\n",
        "    lr_scheduler = get_scheduler(\n",
        "        \"linear\",\n",
        "        optimizer=optimizer,\n",
        "        num_warmup_steps=0,\n",
        "        num_training_steps=num_training_steps\n",
        "    )\n",
        "    early_stopping = EarlyStopping(patience=3, verbose=False)\n",
        " \n",
        "    train_accuracy_metric=load_metric(\"accuracy\")\n",
        "    valid_accuracy_metric=load_metric(\"accuracy\")\n",
        " \n",
        "    train_loss,valid_loss=0,0\n",
        "    pr_train_loss,pr_valid_loss=0,0\n",
        " \n",
        "    progress_bar = tqdm(range(num_training_steps))\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "      train_losses = []\n",
        "      valid_losses = []\n",
        " \n",
        "      model.train()\n",
        "      for batch in train_dataloader:\n",
        "          batch = tuple(t.to(device) for t in batch)\n",
        "          b_input_ids, b_input_mask, b_labels = batch\n",
        "          logits = model(b_input_ids,b_input_mask)\n",
        "          loss=criterion(logits,b_labels)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        " \n",
        "          train_losses.append(loss.item())\n",
        "          predictions = torch.argmax(logits, dim=-1)\n",
        "          train_accuracy_metric.add_batch(predictions=predictions,references=b_labels)\n",
        " \n",
        "          lr_scheduler.step()\n",
        "          optimizer.zero_grad()\n",
        "          progress_bar.update(1)\n",
        " \n",
        "      model.eval()\n",
        "      for batch in validation_dataloader:\n",
        "          batch = tuple(t.to(device) for t in batch)\n",
        "          b_input_ids, b_input_mask, b_labels = batch\n",
        "          with torch.no_grad():\n",
        "              logits = model(b_input_ids,b_input_mask)\n",
        "          loss=criterion(logits,b_labels)\n",
        " \n",
        "          valid_losses.append(loss.item())\n",
        "          predictions = torch.argmax(logits, dim=-1)\n",
        "          valid_accuracy_metric.add_batch(predictions=predictions,references=b_labels)\n",
        " \n",
        "      pr_train_loss=train_loss\n",
        "      train_loss = np.average(train_losses)\n",
        "      pr_valid_loss=valid_loss\n",
        "      valid_loss = np.average(valid_losses)\n",
        " \n",
        "      early_stopping(valid_loss, model)\n",
        "          \n",
        "      if early_stopping.early_stop:\n",
        "          print(\"Early stopping\")\n",
        "          valid_loss=pr_valid_loss\n",
        "          train_loss=pr_train_loss\n",
        "          break\n",
        "\n",
        "      train_accuracy=train_accuracy_metric.compute()['accuracy']\n",
        "      valid_accuracy=valid_accuracy_metric.compute()['accuracy']\n",
        "\n",
        "      print(\"EPOCH: {}\".format(epoch+1),\n",
        "            \"| Train accuracy: {:7.5f}\".format(train_accuracy),\n",
        "            \"| Train loss: {:7.5f}\".format(train_loss),\n",
        "            \"| Validation accuracy: {:7.5f}\".format(valid_accuracy),\n",
        "            \"| Validation loss: {:7.5f}\".format(valid_loss))\n",
        " \n",
        "    return train_accuracy,train_loss,valid_accuracy,valid_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5butv1ImLHWZ"
      },
      "source": [
        "#Function to train and test a model\n",
        "def train_and_test_model(learning_rate,train_dataloader,test_dataloader): \n",
        " \n",
        "    model = LSTM(xlnet)\n",
        "    model.cuda()\n",
        " \n",
        "    optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
        "    criterion=nn.CrossEntropyLoss()\n",
        "\n",
        "    num_epochs = 4\n",
        "    num_training_steps = num_epochs * len(train_dataloader)\n",
        "    lr_scheduler = get_scheduler(\n",
        "        \"linear\",\n",
        "        optimizer=optimizer,\n",
        "        num_warmup_steps=0,\n",
        "        num_training_steps=num_training_steps\n",
        "    )\n",
        " \n",
        "    train_accuracy_metric=load_metric(\"accuracy\")\n",
        "    test_accuracy_metric=load_metric(\"accuracy\")\n",
        "    test_precision_metric=load_metric(\"precision\")\n",
        "    test_recall_metric=load_metric(\"recall\")\n",
        "    test_f1_metric=load_metric(\"f1\")\n",
        "\n",
        "    train_loss,test_loss=0,0\n",
        " \n",
        "    progress_bar = tqdm(range(num_training_steps))\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "      train_losses = []\n",
        "      model.train()\n",
        "      for batch in train_dataloader:\n",
        "          batch = tuple(t.to(device) for t in batch)\n",
        "          b_input_ids, b_input_mask, b_labels = batch\n",
        "          logits = model(b_input_ids,b_input_mask)\n",
        "          loss=criterion(logits,b_labels)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        " \n",
        "          train_losses.append(loss.item())\n",
        "          predictions = torch.argmax(logits, dim=-1)\n",
        "          train_accuracy_metric.add_batch(predictions=predictions,references=b_labels)\n",
        " \n",
        "          lr_scheduler.step()\n",
        "          optimizer.zero_grad()\n",
        "          progress_bar.update(1)\n",
        "\n",
        "      train_accuracy=train_accuracy_metric.compute()['accuracy']\n",
        "      train_loss = np.average(train_losses)\n",
        "      print(\"EPOCH: {}\".format(epoch+1),\n",
        "            \"| Train accuracy: {:7.5f}\".format(train_accuracy),\n",
        "            \"| Train loss: {:7.5f}\".format(train_loss))\n",
        " \n",
        "    test_losses = []\n",
        "    model.eval()\n",
        "    for batch in test_dataloader:\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        with torch.no_grad():\n",
        "            logits = model(b_input_ids,b_input_mask)\n",
        "        loss=criterion(logits,b_labels)\n",
        " \n",
        "        test_losses.append(loss.item())\n",
        "        predictions = torch.argmax(logits, dim=-1)\n",
        "        test_accuracy_metric.add_batch(predictions=predictions,references=b_labels)\n",
        "        test_precision_metric.add_batch(predictions=predictions,references=b_labels)\n",
        "        test_recall_metric.add_batch(predictions=predictions,references=b_labels)\n",
        "        test_f1_metric.add_batch(predictions=predictions,references=b_labels)\n",
        " \n",
        "    test_loss = np.average(test_losses)\n",
        "    test_accuracy=test_accuracy_metric.compute()['accuracy']\n",
        "    test_precision=test_precision_metric.compute()['precision']\n",
        "    test_recall=test_recall_metric.compute()['recall']\n",
        "    test_f1=test_f1_metric.compute()['f1']\n",
        "\n",
        "    print(\"Learning Rate: {}\".format(learning_rate)+\n",
        "        \" | Test accuracy: {:7.5f}\".format(test_accuracy)+\n",
        "        \" | Test loss: {:7.5f}\".format(test_loss)+\n",
        "        \" | Test precision: {:7.5f}\".format(test_precision)+\n",
        "        \" | Test recall: {:7.5f}\".format(test_recall)+\n",
        "        \" | Test f1 score: {:7.5f}\".format(test_f1))\n",
        " \n",
        "    return train_accuracy,train_loss,test_accuracy,test_loss,test_precision,test_recall,test_f1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cdqh_Xd4AJFv"
      },
      "source": [
        "##Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jPLEaBDmLLy"
      },
      "source": [
        "# prepare cross validation\n",
        "outer_cv = KFold(n_splits=10, shuffle=True, random_state= 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1e6s4fB8mMCy"
      },
      "source": [
        "train_valid_ids=[]\n",
        "test_ids=[]\n",
        "#Split in 10 folds - 9 folds for training+validation set and 1 fold for test set\n",
        "for train_valid_id, test_id in outer_cv.split(input_ids):\n",
        "  train_valid_ids.append(train_valid_id)\n",
        "  test_ids.append(test_id)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kG17sHGmSnn"
      },
      "source": [
        "# #To save train_valid_set and test_set iterations of outer cross validation\n",
        "# torch.save(train_valid_ids, 'train_valid_ids.pt')\n",
        "# torch.save(test_ids, 'test_ids.pt')\n",
        "# buffer = io.BytesIO()\n",
        "# torch.save(train_valid_ids, buffer)\n",
        "# torch.save(test_ids, buffer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4i9N2OwmTc4"
      },
      "source": [
        "# #Loading train_valid_set and test_set\n",
        "# with open('train_valid_ids.pt', 'rb') as f:\n",
        "#   buffer = io.BytesIO(f.read())\n",
        "# train_valid_ids=torch.load(buffer)\n",
        "\n",
        "# with open('test_ids.pt', 'rb') as f:\n",
        "#   buffer = io.BytesIO(f.read())\n",
        "# test_ids=torch.load(buffer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQ4l4M0sAMPf"
      },
      "source": [
        "###K-fold Cross Valiadtion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-3NHnWr3S6d"
      },
      "source": [
        "# lr=0.005\n",
        "# # FOR CROSS VALIDATION\n",
        "# train_accuracy,train_loss,test_loss,test_accuracy,test_recall,test_precision,test_f1=[],[],[],[],[],[],[]\n",
        "\n",
        "# #Split in 10 folds - 9 folds for training+validation set and 1 fold for test set\n",
        "# for outer_cv_count in range(10):\n",
        "\n",
        "#   train_val_dataloader=create_dataloader(input_ids[train_valid_ids[outer_cv_count]],\n",
        "#                                          attention_masks[train_valid_ids[outer_cv_count]],\n",
        "#                                          labels[train_valid_ids[outer_cv_count]])\n",
        "\n",
        "#   test_dataloader=create_dataloader(input_ids[test_ids[outer_cv_count]],\n",
        "#                                     attention_masks[test_ids[outer_cv_count]],\n",
        "#                                     labels[test_ids[outer_cv_count]])\n",
        "\n",
        "#   tr_accuracy,tr_loss,ts_accuracy,ts_loss,ts_precision,ts_recall,ts_f1=train_and_test_model(lr,train_dataloader,valid_dataloader,test_dataloader)    \n",
        "\n",
        "#   train_accuracy.append(tr_accuracy)    \n",
        "#   train_loss.append(tr_loss)\n",
        "#   test_accuracy.append(ts_accuracy)\n",
        "#   test_loss.append(ts_loss)\n",
        "#   test_precision.append(ts_precision)\n",
        "#   test_recall.append(ts_recall)\n",
        "#   test_f1.append(ts_f1)\n",
        "#   print('----------------------------------------------------------------------------------------------------')\n",
        "\n",
        "#   torch.cuda.empty_cache() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYpf6nLr-Ppb"
      },
      "source": [
        "# print(\"Train accuracy:\",torch.std_mean(torch.Tensor(train_accuracy)))\n",
        "# print(\"Train loss:\",torch.std_mean(torch.Tensor(train_loss)))\n",
        "# print(\"Test accuracy:\",torch.std_mean(torch.Tensor(test_accuracy)))\n",
        "# print(\"Test loss:\",torch.std_mean(torch.Tensor(test_loss)))\n",
        "# print(\"Test precision:\",torch.std_mean(torch.Tensor(test_precision)))\n",
        "# print(\"Test recall:\",torch.std_mean(torch.Tensor(test_recall)))\n",
        "# print(\"Test f1:\",torch.std_mean(torch.Tensor(test_f1)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5ShDRfsAPcO"
      },
      "source": [
        "###Nested K-fold Cross Valiadtion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zG5SD48fpD3o"
      },
      "source": [
        "# FOR NESTED CROSS VALIDATION\n",
        "inner_cv = KFold(n_splits=3, shuffle=True, random_state=1)\n",
        "train_val_accuracy,train_val_loss,test_loss,test_accuracy,test_recall,test_precision,test_f1=[],[],[],[],[],[],[]\n",
        "best_learning_rate=[]\n",
        "\n",
        "#Split in 10 folds - 9 folds for training+validation set and 1 fold for test set\n",
        "for outer_cv_count in range(10):\n",
        "\n",
        "  train_val_dataloader=create_dataloader(input_ids[train_valid_ids[outer_cv_count]],\n",
        "                                         attention_masks[train_valid_ids[outer_cv_count]],\n",
        "                                         labels[train_valid_ids[outer_cv_count]])\n",
        "\n",
        "  test_dataloader=create_dataloader(input_ids[test_ids[outer_cv_count]],\n",
        "                                    attention_masks[test_ids[outer_cv_count]],\n",
        "                                    labels[test_ids[outer_cv_count]])\n",
        "\n",
        "  #Check for hyperparameters\n",
        "  learning_rate=[ 3e-4,5e-4,1e-3,2e-3]\n",
        "\n",
        "  mean_train_loss,mean_train_accuracy=[],[]\n",
        "  mean_validation_loss,mean_validation_accuracy=[],[]\n",
        "\n",
        "  #Enumeratig over all hyperparameter combinations\n",
        "  for i in range(learning_rate.__len__()):\n",
        "\n",
        "    inner_cv_count=0\n",
        "    train_loss,train_accuracy=[],[]\n",
        "    validation_loss,validation_accuracy=[],[]\n",
        "\n",
        "    #Split in 3 folds - 2 folds for train set and 1 fold for validation\n",
        "    for train_id, valid_id in inner_cv.split(input_ids[train_valid_ids[outer_cv_count]]):\n",
        "\n",
        "      train_dataloader=create_dataloader(input_ids[train_id],\n",
        "                                        attention_masks[train_id],\n",
        "                                        labels[train_id])\n",
        "      validation_dataloader=create_dataloader(input_ids[valid_id],\n",
        "                                        attention_masks[valid_id],\n",
        "                                        labels[valid_id])\n",
        "\n",
        "      tr_accuracy,tr_loss,vd_accuracy,vd_loss=train_and_validate_model(learning_rate[i],train_dataloader,validation_dataloader)\n",
        "      print(\"MODEL: {}\".format(inner_cv_count+1),\n",
        "            \"| Train accuracy: {:7.5f}\".format(tr_accuracy),\n",
        "            \"| Train loss: {:7.5f}\".format(tr_loss),\n",
        "            \"| Validation accuracy: {:7.5f}\".format(vd_accuracy),\n",
        "            \"| Validation loss: {:7.5f}\".format(vd_loss))\n",
        "        \n",
        "      train_accuracy.append(tr_accuracy)\n",
        "      train_loss.append(tr_loss)\n",
        "      validation_accuracy.append(vd_accuracy)\n",
        "      validation_loss.append(vd_loss)\n",
        "      inner_cv_count+=1\n",
        "\n",
        "      torch.cuda.empty_cache() \n",
        "\n",
        "    mean_train_accuracy.append(sum(train_accuracy)/3)\n",
        "    mean_train_loss.append(sum(train_loss)/3)\n",
        "    mean_validation_accuracy.append(sum(validation_accuracy)/3)\n",
        "    mean_validation_loss.append(sum(validation_loss)/3)\n",
        "    \n",
        "    print(\"P: \"+str(learning_rate[i])+\n",
        "              \" | Mean train accuracy: {:7.5f}\".format(mean_train_accuracy[i])+\n",
        "              \" | Mean train loss: {:7.5f}\".format(mean_train_loss[i]) +\n",
        "              \" | Mean validation accuracy: {:7.5f}\".format(mean_validation_accuracy[i])+\n",
        "              \" | Mean validation loss: {:7.5f}\".format(mean_validation_loss[i]))\n",
        "    print(\"--------------------------------------------------------------------------------------------------\")\n",
        "\n",
        "  best_learning_rate.append(learning_rate[mean_validation_accuracy.index(max(mean_validation_accuracy))])\n",
        "  tr_accuracy,tr_loss,ts_accuracy,ts_loss,ts_precision,ts_recall,ts_f1=train_and_test_model(best_learning_rate[outer_cv_count],train_val_dataloader,test_dataloader)\n",
        "\n",
        "  train_val_accuracy.append(tr_accuracy)    \n",
        "  train_val_loss.append(tr_loss)\n",
        "  test_accuracy.append(ts_accuracy)\n",
        "  test_loss.append(ts_loss)\n",
        "  test_precision.append(ts_precision)\n",
        "  test_recall.append(ts_recall)\n",
        "  test_f1.append(ts_f1)\n",
        "\n",
        "  print(\"Learning Rate: {}\".format(best_learning_rate[outer_cv_count])+\n",
        "         \" | Train accuracy: {:7.5f}\".format(train_val_accuracy[outer_cv_count])+ \n",
        "         \" | Train loss: {:7.5f}\".format(train_val_loss[outer_cv_count]) +\n",
        "         \" | Test accuracy: {:7.5f}\".format(test_accuracy[outer_cv_count])+\n",
        "         \" | Test loss: {:7.5f}\".format(test_loss[outer_cv_count])+\n",
        "         \" | Test precision: {:7.5f}\".format(test_precision[outer_cv_count])+\n",
        "         \" | Test recall: {:7.5f}\".format(test_recall[outer_cv_count])+\n",
        "         \" | Test f1 score: {:7.5f}\".format(test_f1[outer_cv_count]))\n",
        "  print('----------------------------------------------------------------------------------------------------')\n",
        "\n",
        "  torch.cuda.empty_cache() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4f5NWiQI5muC"
      },
      "source": [
        "print(\"Train accuracy:\",torch.std_mean(torch.Tensor(train_val_accuracy)))\n",
        "print(\"Train loss:\",torch.std_mean(torch.Tensor(train_val_loss)))\n",
        "print(\"Test accuracy:\",torch.std_mean(torch.Tensor(test_accuracy)))\n",
        "print(\"Test loss:\",torch.std_mean(torch.Tensor(test_loss)))\n",
        "print(\"Test precision:\",torch.std_mean(torch.Tensor(test_precision)))\n",
        "print(\"Test recall:\",torch.std_mean(torch.Tensor(test_recall)))\n",
        "print(\"Test f1:\",torch.std_mean(torch.Tensor(test_f1)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17BQAryQAUI-"
      },
      "source": [
        "##Result\n",
        "```\n",
        "Learning Rate: 0.0005 | Train accuracy: 0.72229 | Train loss: 0.56164 | Test accuracy: 0.75362 | Test loss: 0.53775 | Test precision: 0.66667 | Test recall: 0.64000 | Test f1 score: 0.65306\n",
        "Learning Rate: 0.0005 | Train accuracy: 0.73582 | Train loss: 0.55110 | Test accuracy: 0.70145 | Test loss: 0.53384 | Test precision: 0.54783 | Test recall: 0.55263 | Test f1 score: 0.55022\n",
        "Learning Rate: 0.0005 | Train accuracy: 0.71424 | Train loss: 0.57674 | Test accuracy: 0.75072 | Test loss: 0.54094 | Test precision: 0.66667 | Test recall: 0.49123 | Test f1 score: 0.56566\n",
        "Learning Rate: 0.001  | Train accuracy: 0.73872 | Train loss: 0.55413 | Test accuracy: 0.75072 | Test loss: 0.52436 | Test precision: 0.76000 | Test recall: 0.55072 | Test f1 score: 0.63866\n",
        "Learning Rate: 0.001  | Train accuracy: 0.64916 | Train loss: 0.64447 | Test accuracy: 0.68406 | Test loss: 0.62499 | Test precision: 0.57955 | Test recall: 0.41463 | Test f1 score: 0.48341\n",
        "Learning Rate: 0.0005 | Train accuracy: 0.72294 | Train loss: 0.56237 | Test accuracy: 0.69275 | Test loss: 0.58049 | Test precision: 0.58889 | Test recall: 0.43443 | Test f1 score: 0.50000\n",
        "Learning Rate: 0.001  | Train accuracy: 0.66173 | Train loss: 0.62438 | Test accuracy: 0.66087 | Test loss: 0.60722 | Test precision: 0.53271 | Test recall: 0.45968 | Test f1 score: 0.49351\n",
        "Learning Rate: 0.0003 | Train accuracy: 0.71521 | Train loss: 0.56329 | Test accuracy: 0.72464 | Test loss: 0.56430 | Test precision: 0.70833 | Test recall: 0.50370 | Test f1 score: 0.58874\n",
        "Learning Rate: 0.0005 | Train accuracy: 0.73389 | Train loss: 0.55833 | Test accuracy: 0.73623 | Test loss: 0.53066 | Test precision: 0.69318 | Test recall: 0.48800 | Test f1 score: 0.57277\n",
        "Learning Rate: 0.0005 | Train accuracy: 0.72496 | Train loss: 0.56617 | Test accuracy: 0.75581 | Test loss: 0.51618 | Test precision: 0.64286 | Test recall: 0.56250 | Test f1 score: 0.60000\n",
        "```\n",
        "Train accuracy: (tensor(0.0310), tensor(0.7119))\n",
        "\n",
        "Train loss: (tensor(0.0318), tensor(0.5763))\n",
        "\n",
        "Test accuracy: (tensor(0.0341), tensor(0.7211))\n",
        "\n",
        "Test loss: (tensor(0.0370), tensor(0.5561))\n",
        "\n",
        "Test precision: (tensor(0.0742), tensor(0.6387))\n",
        "\n",
        "Test recall: (tensor(0.0678), tensor(0.5098))\n",
        "\n",
        "Test f1: (tensor(0.0589), tensor(0.5646))"
      ]
    }
  ]
}