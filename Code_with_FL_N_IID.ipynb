{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Code_with_FL_N-IID",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Priyanka-Sachan/Complaint-Identification-using-FL/blob/master/Code_with_FL_N_IID.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IoOlZk6KaB-"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tJi_7GgKaCC"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install sentencepiece\n",
        "!pip install datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DpBfDfgKaCD"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from fastai.text import *\n",
        "from google.colab import files\n",
        "\n",
        "import transformers\n",
        "transformers.logging.set_verbosity_error()\n",
        "from transformers import AdamW\n",
        "from transformers import XLNetModel, XLNetTokenizer, XLNetForSequenceClassification\n",
        "from transformers import get_scheduler\n",
        "from datasets import load_metric\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "import math\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EG_keBCS4g1F"
      },
      "source": [
        "# For Reproducibility\n",
        "SEED=9\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92xAoCTmKaCE"
      },
      "source": [
        "class EarlyStopping:\n",
        "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
        "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): How long to wait after last time validation loss improved.\n",
        "                            Default: 7\n",
        "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
        "                            Default: False\n",
        "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
        "                            Default: 0\n",
        "            path (str): Path for the checkpoint to be saved to.\n",
        "                            Default: 'checkpoint.pt'\n",
        "            trace_func (function): trace print function.\n",
        "                            Default: print            \n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "        self.path = path\n",
        "        self.trace_func = trace_func\n",
        "    def __call__(self, val_loss, model):\n",
        "\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        '''Saves model when validation loss decrease.'''\n",
        "        if self.verbose:\n",
        "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), self.path)\n",
        "        self.val_loss_min = val_loss"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORMJtxpPKaCG"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "torch.cuda.get_device_name(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSoUcAvo_slO"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6M7_IyeSp0d"
      },
      "source": [
        "def create_dataloader(input_ids,masks,labels):\n",
        "\n",
        "  input_ids=torch.tensor(input_ids)\n",
        "  masks=torch.tensor(masks)\n",
        "  labels=torch.tensor(labels)\n",
        "\n",
        "  data = TensorDataset(input_ids,masks,labels)\n",
        "  sampler = SequentialSampler(data)\n",
        "  dataloader = DataLoader(data, sampler=sampler, batch_size=16) \n",
        "\n",
        "  return dataloader"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beNGctgf_tU3"
      },
      "source": [
        "# To train main model intially with amazon reviews\n",
        "def train_main_model(model,optimizer):\n",
        "\n",
        "  path = untar_data(URLs.AMAZON_REVIEWS, dest = \"Data\")\n",
        "  df = pd.read_csv(path/'train.csv', header=None, names=['rating', 'title', 'review'],  nrows=10000)\n",
        "\n",
        "  label=[]\n",
        "  for rating in df.rating.values:\n",
        "    if(rating>2):\n",
        "      label.append(0)\n",
        "    else:\n",
        "      label.append(1)\n",
        "  df['label']=label\n",
        "\n",
        "  sentences=df.review.values\n",
        "  tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased', do_lower_case=True)\n",
        "  MAX_LEN=49\n",
        "  tokens= [tokenizer(sentence, padding='max_length',truncation=\"only_first\", max_length=MAX_LEN) for sentence in sentences]\n",
        "\n",
        "  input_ids=np.asarray([np.asarray(token['input_ids']) for token in tokens])\n",
        "  attention_masks=np.asarray([np.asarray(token['attention_mask']) for token in tokens])\n",
        "  labels=df.label.values\n",
        " \n",
        "  train_inputs, valid_inputs, train_masks, valid_masks,train_labels, valid_labels = train_test_split(input_ids,attention_masks, labels,random_state=42, test_size=0.2)\n",
        "\n",
        "  train_dataloader=create_dataloader(train_inputs,train_masks,train_labels)\n",
        "  validation_dataloader=create_dataloader(valid_inputs,valid_masks,valid_labels)\n",
        "\n",
        "  train_accuracy,train_loss,valid_accuracy,valid_loss=train_and_validate_model(model,optimizer,train_dataloader,validation_dataloader)\n",
        " \n",
        "  torch.save(model.state_dict(), F\"/content/gdrive/My Drive/Innovation_Lab/main_model.pt\" )\n",
        "  torch.save(optimizer.state_dict(), F\"/content/gdrive/My Drive/Innovation_Lab/main_optimizer.pt\" )"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vc2ydPR8-7bl"
      },
      "source": [
        "# To extract features from complaints data\n",
        "def get_features():\n",
        "\n",
        "  uploaded = files.upload()\n",
        "  df = pd.read_csv(\"complaints-data.csv\", header=None, names=['id', 'tweet', 'y', 'industry'])\n",
        "\n",
        "  industry_code=[]\n",
        "  for industry in df.industry.values:\n",
        "    if industry=='apparel':\n",
        "      industry_code.append(0)\n",
        "    elif industry=='cars':\n",
        "      industry_code.append(1)\n",
        "    elif industry=='electronics':\n",
        "      industry_code.append(2)\n",
        "    elif industry=='food':\n",
        "      industry_code.append(3)\n",
        "    elif industry=='retail':\n",
        "      industry_code.append(4)\n",
        "    elif industry=='services':\n",
        "      industry_code.append(5)\n",
        "    elif industry=='software':\n",
        "      industry_code.append(6)\n",
        "    elif industry=='transport':\n",
        "      industry_code.append(7)\n",
        "    elif industry=='other':\n",
        "      industry_code.append(8)\n",
        "    else :\n",
        "      industry_code.append(9)\n",
        "  df['industry_code']=industry_code\n",
        "\n",
        "  sentences=df.tweet.values\n",
        "  tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased', do_lower_case=True)\n",
        "  MAX_LEN=49\n",
        "  tokens= [tokenizer(sentence, padding='max_length',truncation=\"only_first\", max_length=MAX_LEN) for sentence in sentences]\n",
        "\n",
        "  input_ids=np.asarray([np.asarray(token['input_ids']) for token in tokens])\n",
        "  attention_masks=np.asarray([np.asarray(token['attention_mask']) for token in tokens])\n",
        "  labels=df.y.values\n",
        "  industry_code=df.industry_code.values\n",
        "\n",
        "  return input_ids,attention_masks,labels,industry_code"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3H9mTZ96HDWP"
      },
      "source": [
        "# Shuffling and dividing the data into 9 parts based on industry\n",
        "def split_and_shuffle_samples(industry_codes, seed):\n",
        "\n",
        "    samples=pd.DataFrame(industry_codes,columns=[\"samples\"])\n",
        "    samples[\"i\"]=np.arange(len(samples))\n",
        "    sample_dict = dict()\n",
        "\n",
        "    for i in range(9):\n",
        "        var_name=\"sample\" + str(i)\n",
        "        sample_info=samples[samples[\"samples\"]==i]\n",
        "        np.random.seed(seed)\n",
        "        sample_info=np.random.permutation(sample_info)\n",
        "        sample_info=pd.DataFrame(sample_info, columns=[\"samples\",\"i\"])\n",
        "        sample_dict.update({var_name: sample_info })\n",
        "        \n",
        "    return sample_dict"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnayZ83EHIOj"
      },
      "source": [
        "# Distributes input ids, attention masks and labels to nodes in dictionary\n",
        "def create_niid_subsamples(sample_dict, input_ids,attention_masks,labels):\n",
        "  \n",
        "    input_ids_dict= dict()\n",
        "    attention_masks_dict=dict()\n",
        "    labels_dict= dict()\n",
        "    \n",
        "    for i in range(len(sample_dict)):  \n",
        "\n",
        "        input_id_name= \"input_id\"+str(i)\n",
        "        attention_mask_name=\"attention_mask\"+str(i)\n",
        "        label_name= \"label\"+str(i)\n",
        "        sample_name=\"sample\"+str(i)\n",
        "        \n",
        "        indices=np.sort(np.array(sample_dict[sample_name][\"i\"]))\n",
        "        \n",
        "        input_ids_info= input_ids[indices]\n",
        "        input_ids_dict.update({input_id_name : input_ids_info})\n",
        "\n",
        "        attention_masks_info= attention_masks[indices]\n",
        "        attention_masks_dict.update({attention_mask_name : attention_masks_info})\n",
        "        \n",
        "        labels_info= labels[indices]\n",
        "        labels_dict.update({label_name : labels_info})\n",
        "        \n",
        "    return input_ids_dict,attention_masks_dict, labels_dict"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bViXVzhaKkuY"
      },
      "source": [
        "def train_valid_test_split(input_ids_dict, attention_masks_dict, labels_dict):\n",
        "    \n",
        "    for i in range(number_of_samples):\n",
        "\n",
        "        input_id_name= \"input_id\"+str(i)\n",
        "        attention_mask_name=\"attention_mask\"+str(i)\n",
        "        label_name= \"label\"+str(i)\n",
        "\n",
        "        input_ids=input_ids_dict[input_id_name]\n",
        "        attention_masks=attention_masks_dict[attention_mask_name]\n",
        "        labels=labels_dict[label_name]\n",
        "\n",
        "        train_inputs, val_test_inputs, train_masks, val_test_masks,train_labels, val_test_labels = train_test_split(input_ids,attention_masks, labels,random_state=42, test_size=0.2)\n",
        "        validation_inputs, test_inputs,validation_masks, test_masks, validation_labels, test_labels = train_test_split(val_test_inputs,val_test_masks, val_test_labels,random_state=42, test_size=0.5)\n",
        "        \n",
        "        input_ids_info=dict()\n",
        "        input_ids_info.update({'all':input_ids, 'train':train_inputs,'valid':validation_inputs,'test':test_inputs})\n",
        "        input_ids_dict.update({input_id_name : input_ids_info})\n",
        "\n",
        "        attention_masks_info= dict()\n",
        "        attention_masks_info.update({'all':attention_masks,'train':train_masks,'valid':validation_masks,'test':test_masks})\n",
        "        attention_masks_dict.update({attention_mask_name : attention_masks_info})\n",
        "        \n",
        "        labels_info= dict()\n",
        "        labels_info.update({'all':labels,'train':train_labels,'valid':validation_labels,'test':test_labels})\n",
        "        labels_dict.update({label_name : labels_info})\n",
        "\n",
        "    return input_ids_dict, attention_masks_dict, labels_dict"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQgXPRmKKaCS"
      },
      "source": [
        "# To train and validate local models\n",
        "def train_and_validate_model(model,optimizer,train_dataloader,validation_dataloader): \n",
        " \n",
        "    model.cuda()\n",
        "\n",
        "    num_epochs = 4\n",
        "    num_training_steps = num_epochs * len(train_dataloader)\n",
        "    lr_scheduler = get_scheduler(\n",
        "        \"linear\",\n",
        "        optimizer=optimizer,\n",
        "        num_warmup_steps=0,\n",
        "        num_training_steps=num_training_steps\n",
        "    )\n",
        "    early_stopping = EarlyStopping(patience=3, verbose=False)\n",
        " \n",
        "    train_accuracy_metric=load_metric(\"accuracy\")\n",
        "    valid_accuracy_metric=load_metric(\"accuracy\")\n",
        " \n",
        "    train_loss,valid_loss=0,0\n",
        "    pr_train_loss,pr_valid_loss=0,0\n",
        " \n",
        "    progress_bar = tqdm(range(num_training_steps))\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "      train_losses = []\n",
        "      valid_losses = []\n",
        " \n",
        "      model.train()\n",
        "      for batch in train_dataloader:\n",
        "          batch = tuple(t.to(device) for t in batch)\n",
        "          b_input_ids, b_input_mask, b_labels = batch\n",
        "          b_input_ids.cuda()\n",
        "          b_input_mask.cuda()\n",
        "          b_labels.cuda()\n",
        "          outputs = model(input_ids=b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
        "          loss = outputs.loss\n",
        "          logits = outputs.logits\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          lr_scheduler.step()\n",
        " \n",
        "          train_losses.append(loss.item())\n",
        "          predictions = torch.argmax(logits, dim=-1)\n",
        "          train_accuracy_metric.add_batch(predictions=predictions,references=b_labels)\n",
        " \n",
        "          optimizer.zero_grad()\n",
        "          progress_bar.update(1)\n",
        " \n",
        "      model.eval()\n",
        "      for batch in validation_dataloader:\n",
        "          batch = tuple(t.to(device) for t in batch)\n",
        "          b_input_ids, b_input_mask, b_labels = batch\n",
        "          b_input_ids.cuda()\n",
        "          b_input_mask.cuda()\n",
        "          b_labels.cuda()\n",
        "          with torch.no_grad():\n",
        "              outputs = model(input_ids=b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
        "          loss = outputs.loss\n",
        "          logits = outputs.logits\n",
        " \n",
        "          valid_losses.append(loss.item())\n",
        "          predictions = torch.argmax(logits, dim=-1)\n",
        "          valid_accuracy_metric.add_batch(predictions=predictions,references=b_labels)\n",
        " \n",
        "      pr_train_loss=train_loss\n",
        "      train_loss = np.average(train_losses)\n",
        "      pr_valid_loss=valid_loss\n",
        "      valid_loss = np.average(valid_losses)\n",
        " \n",
        "      early_stopping(valid_loss, model)\n",
        "          \n",
        "      if early_stopping.early_stop:\n",
        "          print(\"Early stopping\")\n",
        "          valid_loss=pr_valid_loss\n",
        "          train_loss=pr_train_loss\n",
        "          break\n",
        "\n",
        "      train_accuracy=train_accuracy_metric.compute()['accuracy']\n",
        "      valid_accuracy=valid_accuracy_metric.compute()['accuracy']\n",
        "\n",
        "      print(\"EPOCH: {}\".format(epoch+1),\n",
        "            \"| Train accuracy: {:7.5f}\".format(train_accuracy),\n",
        "            \"| Train loss: {:7.5f}\".format(train_loss),\n",
        "            \"| Validation accuracy: {:7.5f}\".format(valid_accuracy),\n",
        "            \"| Validation loss: {:7.5f}\".format(valid_loss))\n",
        "\n",
        "    model.cpu()\n",
        "    torch.cuda.empty_cache() \n",
        " \n",
        "    return train_accuracy,train_loss,valid_accuracy,valid_loss"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZZTSVXHjlKX"
      },
      "source": [
        "# Evaluate models\n",
        "def test_model(model,test_dataloader):\n",
        "\n",
        "    model.cuda()\n",
        "\n",
        "    test_losses=[]\n",
        "    test_accuracy_metric=load_metric(\"accuracy\")\n",
        "    test_precision_metric=load_metric(\"precision\")\n",
        "    test_recall_metric=load_metric(\"recall\")\n",
        "    test_f1_metric=load_metric(\"f1\")\n",
        "    \n",
        "    model.eval()\n",
        "    for batch in test_dataloader:\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        with torch.no_grad():\n",
        "            outputs = model(input_ids=b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
        "        loss = outputs.loss\n",
        "        logits = outputs.logits\n",
        " \n",
        "        test_losses.append(loss.item())\n",
        "        predictions = torch.argmax(logits, dim=-1)\n",
        "        test_accuracy_metric.add_batch(predictions=predictions,references=b_labels)\n",
        "        test_precision_metric.add_batch(predictions=predictions,references=b_labels)\n",
        "        test_recall_metric.add_batch(predictions=predictions,references=b_labels)\n",
        "        test_f1_metric.add_batch(predictions=predictions,references=b_labels)\n",
        " \n",
        "    test_loss = np.average(test_losses)\n",
        "    test_accuracy=test_accuracy_metric.compute()['accuracy']\n",
        "    test_precision=test_precision_metric.compute()['precision']\n",
        "    test_recall=test_recall_metric.compute()['recall']\n",
        "    test_f1=test_f1_metric.compute()['f1']\n",
        "\n",
        "    model.cpu()\n",
        " \n",
        "    return test_accuracy,test_loss,test_precision,test_recall,test_f1"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9BbfC30HU9J"
      },
      "source": [
        "# Creates a model and optimizer for each node\n",
        "def create_model_optimizer_dict(number_of_samples):\n",
        "\n",
        "    model_dict = dict()\n",
        "    optimizer_dict= dict()\n",
        "    \n",
        "    for i in range(number_of_samples):\n",
        "\n",
        "        model_name=\"model\"+str(i)\n",
        "        model_info=XLNetForSequenceClassification.from_pretrained(pretrained_model_name_or_path=\"xlnet-base-cased\", num_labels=2)\n",
        "        model_dict.update({model_name : model_info })\n",
        "\n",
        "        optimizer_name=\"optimizer\"+str(i)\n",
        "        optimizer_info = AdamW(model_dict[model_name].parameters(),lr=1e-5)\n",
        "        optimizer_dict.update({optimizer_name : optimizer_info })\n",
        "        \n",
        "    return model_dict, optimizer_dict "
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xxpu5sksHpzF"
      },
      "source": [
        "# Load all trained local models\n",
        "def load_all_models(number_of_samples):\n",
        "\n",
        "    model_dict = dict()\n",
        "    optimizer_dict= dict()\n",
        "    \n",
        "    for i in range(number_of_samples):\n",
        "\n",
        "        model=XLNetForSequenceClassification.from_pretrained(pretrained_model_name_or_path=\"xlnet-base-cased\", num_labels=2)\n",
        "        optimizer=AdamW(model.parameters(),lr=1e-5)\n",
        "\n",
        "        model_name=\"model\"+str(i)\n",
        "        model.load_state_dict(torch.load( F\"/content/gdrive/My Drive/Innovation_Lab/NIID/client\"+str(i)+\".pt\"))\n",
        "        model_dict.update({model_name : model })\n",
        "\n",
        "        optimizer_name=\"optimizer\"+str(i)\n",
        "        optimizer_dict.update({optimizer_name : optimizer })\n",
        "        \n",
        "    return model_dict, optimizer_dict "
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdq_IfeJH6uE"
      },
      "source": [
        "# Trains individual local models in nodes\n",
        "def start_train_end_node_process(clients_to_be_trained):\n",
        "  \n",
        "    for i in clients_to_be_trained: \n",
        "\n",
        "        model=model_dict[name_of_models[i]]\n",
        "        optimizer=optimizer_dict[name_of_optimizers[i]]\n",
        "\n",
        "        input_ids=input_ids_dict[name_of_input_ids_sets[i]]\n",
        "        attention_masks=attention_masks_dict[name_of_attention_masks_sets[i]]\n",
        "        labels=labels_dict[name_of_labels_sets[i]]\n",
        "\n",
        "        train_dataloader=create_dataloader(input_ids['train'],attention_masks['train'],labels['train'])\n",
        "        validation_dataloader=create_dataloader(input_ids['valid'],attention_masks['valid'],labels['valid'])\n",
        "        test_dataloader=create_dataloader(input_ids['test'],attention_masks['test'],labels['test'])\n",
        "\n",
        "        train_accuracy,train_loss,valid_accuracy,valid_loss=train_and_validate_model(model,optimizer,train_dataloader,validation_dataloader)\n",
        "        \n",
        "        print(\"CLIENT: {}\".format(i+1) + \n",
        "              \" | Train accuracy: {:7.5f}\".format(train_accuracy)+ \n",
        "              \" | Train loss: {:7.5f}\".format(train_loss) +\n",
        "              \" | Validation accuracy: {:7.5f}\".format(valid_accuracy)+\n",
        "              \" | Validation loss: {:7.5f}\".format(valid_loss))\n",
        "        \n",
        "        test_accuracy,test_loss,test_precision,test_recall,test_f1=test_model(model,test_dataloader)\n",
        "\n",
        "        print(\"CLIENT: {}\".format(i+1) + \n",
        "              \" | Test accuracy: {:7.5f}\".format(test_accuracy)+ \n",
        "              \" | Test loss: {:7.5f}\".format(test_loss) +\n",
        "              \" | Test precision: {:7.5f}\".format(test_precision)+\n",
        "              \" | Test recall: {:7.5f}\".format(test_recall)+\n",
        "              \" | Test f1: {:7.5f}\".format(test_f1))\n",
        "        \n",
        "        torch.save(model.state_dict(), F\"/content/gdrive/My Drive/Innovation_Lab/NIID/client\"+str(i)+\".pt\" )"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m370kqzUJMXe"
      },
      "source": [
        "# Sends the averaged weights of individual nodes to the main model and sets them as the new weights of the main model\n",
        "def get_averaged_weights_and_update_main_model(model_dict, clients_to_be_trained):\n",
        "\n",
        "    with torch.no_grad():\n",
        "        main_model.cuda()\n",
        "\n",
        "        f=0\n",
        "        for i in clients_to_be_trained:\n",
        "            model_dict[\"model\"+str(i)].cuda()\n",
        "\n",
        "            for client_parameters,main_model_parameters in zip(model_dict[\"model\"+str(i)].parameters(),main_model.parameters()):\n",
        "\n",
        "                if f==0:\n",
        "                    main_model_parameters.data=client_parameters.data.clone().detach()\n",
        "                    main_model_parameters.data/=clients_to_be_trained.__len__()\n",
        "                else:\n",
        "                    main_model_parameters.data+=client_parameters.data/clients_to_be_trained.__len__()\n",
        "\n",
        "            f=1\n",
        "\n",
        "            model_dict[\"model\"+str(i)].cpu()\n",
        "\n",
        "        main_model.cpu()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ccyykTYbwk4"
      },
      "source": [
        "def get_test_data(clients_to_be_tested,group):\n",
        "\n",
        "  test_input_ids,test_attention_masks,test_labels=[],[],[]\n",
        "\n",
        "  for i in clients_to_be_tested:\n",
        "\n",
        "    test_input_ids.extend(input_ids_dict[name_of_input_ids_sets[i]][group])\n",
        "    test_attention_masks.extend(attention_masks_dict[name_of_attention_masks_sets[i]][group])\n",
        "    test_labels.extend(labels_dict[name_of_labels_sets[i]][group])\n",
        "\n",
        "  test_dataloader=create_dataloader(test_input_ids,test_attention_masks,test_labels)\n",
        "\n",
        "  return test_dataloader"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ud2B7v5sJj5H"
      },
      "source": [
        "# Compares the accuracy of the main model and the local model running on each node\n",
        "def compare_local_and_merged_model_performance(clients_to_be_trained,clients_to_be_tested,group):\n",
        "\n",
        "    test_dataloader=get_test_data(clients_to_be_tested,group)\n",
        "\n",
        "    accuracy_table=pd.DataFrame(data=np.zeros((clients_to_be_trained.__len__()+1,5)), columns=[\"Model\", \"Accuracy\", \"Precision\",\"Recall\",\"F1\"])\n",
        "    \n",
        "    accuracy,loss,precision,recall,f1 = test_model(main_model, test_dataloader)\n",
        "    \n",
        "    accuracy_table.loc[0, \"Model\"]=\"Main Model\"\n",
        "    accuracy_table.loc[0, \"Accuracy\"] = accuracy\n",
        "    accuracy_table.loc[0, \"Precision\"] = precision\n",
        "    accuracy_table.loc[0, \"Recall\"] = recall\n",
        "    accuracy_table.loc[0, \"F1\"] = f1\n",
        "\n",
        "    industry=['apparel','cars','electronics','food','retail','services','software','transport','other']\n",
        "\n",
        "    j=1\n",
        "    for i in clients_to_be_trained:\n",
        "\n",
        "        if group=='test':\n",
        "\n",
        "            client=[]\n",
        "            client.append(i);\n",
        "            test_dataloader=get_test_data(client,group)\n",
        "\n",
        "        model=model_dict[name_of_models[i]]\n",
        "        optimizer=optimizer_dict[name_of_optimizers[i]]\n",
        "\n",
        "        accuracy,loss,precision,recall,f1 = test_model(model, test_dataloader)\n",
        "    \n",
        "        accuracy_table.loc[j, \"Model\"]=industry[i]\n",
        "        accuracy_table.loc[j, \"Accuracy\"] = accuracy\n",
        "        accuracy_table.loc[j, \"Precision\"] = precision\n",
        "        accuracy_table.loc[j, \"Recall\"] = recall\n",
        "        accuracy_table.loc[j, \"F1\"] = f1\n",
        "\n",
        "        j=j+1\n",
        "\n",
        "    return accuracy_table"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBu6y9m7KKLB"
      },
      "source": [
        "# To send the merged parameters of the main model to local models\n",
        "def send_main_model_to_nodes_and_update_model_dict(main_model, model_dict, number_of_samples):\n",
        "\n",
        "    with torch.no_grad():\n",
        "        main_model.cuda()\n",
        "\n",
        "        for i in range(number_of_samples):\n",
        "            model_dict[\"model\"+str(i)].cuda()\n",
        "\n",
        "            for client_parameters,main_model_parameters in zip(model_dict[\"model\"+str(i)].parameters(),main_model.parameters()):\n",
        "                client_parameters.data=main_model_parameters.data.clone().detach()\n",
        "\n",
        "            model_dict[\"model\"+str(i)].cpu()\n",
        "            \n",
        "        main_model.cpu()  "
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZQ7mhBzXH-6"
      },
      "source": [
        "###EXPERIMENTATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fr6HabMDHNdS"
      },
      "source": [
        "# Load main model - XLNEtForSequenceClassification, the pretrained XLNet model with a single linear classification layer on top. \n",
        "main_model = XLNetForSequenceClassification.from_pretrained(\"xlnet-base-cased\", num_labels=2)\n",
        "main_optimizer = AdamW(params=main_model.parameters(),lr=1e-5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEN6ac02_4-3"
      },
      "source": [
        "# Initially, training model for once.\n",
        "# train_main_model(main_model,main_optimizer)\n",
        "# Or loading weights from drive\n",
        "main_model.load_state_dict(torch.load( F\"/content/gdrive/My Drive/Innovation_Lab/main_model.pt\"))\n",
        "main_optimizer.load_state_dict(torch.load( F\"/content/gdrive/My Drive/Innovation_Lab/main_optimizer.pt\"))"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rs8k4WhX_-E1"
      },
      "source": [
        "# Getting input ids, attention masks, labels and industry codes from complaints\n",
        "input_ids,attention_masks,labels,industry_codes=get_features()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RaVR16b5R6gi"
      },
      "source": [
        "number_of_samples=9"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMT0NheBJC9C"
      },
      "source": [
        "# Creating clients with train, validation and test dataset\n",
        "id_dict=split_and_shuffle_samples(industry_codes, seed=1) \n",
        "input_ids_dict,attention_masks_dict,labels_dict = create_niid_subsamples(id_dict,input_ids,attention_masks,labels)\n",
        "input_ids_dict,attention_masks_dict,labels_dict = train_valid_test_split(input_ids_dict, attention_masks_dict, labels_dict)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1lgx6OkTC8q"
      },
      "source": [
        "# Keys of dicts are being made iterable\n",
        "\n",
        "name_of_input_ids_sets=list(input_ids_dict.keys())\n",
        "name_of_attention_masks_sets=list(attention_masks_dict.keys())\n",
        "name_of_labels_sets=list(labels_dict.keys())"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBxAEyuSlLoK"
      },
      "source": [
        "###Experiment 1\n",
        "Train local domain-specific models, fedAvg it, then test main model across all domain and domain-specific tweets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLzuDH1Plz_s"
      },
      "source": [
        "clients_to_be_trained=[0,1,2,3,4,5,6,7,8]\n",
        "clients_to_be_tested=[0,1,2,3,4,5,6,7,8]"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSKXmpJvlkoT"
      },
      "source": [
        "# Models and optimizers functions in nodes are defined\n",
        "model_dict, optimizer_dict = create_model_optimizer_dict(number_of_samples)\n",
        "name_of_models=list(model_dict.keys())\n",
        "name_of_optimizers=list(optimizer_dict.keys())"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYbmZyIMl-A7"
      },
      "source": [
        "# Updating client models\n",
        "send_main_model_to_nodes_and_update_model_dict(main_model, model_dict, number_of_samples)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1P1RJBXTl-A8"
      },
      "source": [
        "# Models in the nodes are trained\n",
        "start_train_end_node_process(clients_to_be_trained)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJe6qR0MNB5W"
      },
      "source": [
        "# Or load all trained local models\n",
        "model_dict, optimizer_dict = load_all_models(number_of_samples)\n",
        "name_of_models=list(model_dict.keys())\n",
        "name_of_optimizers=list(optimizer_dict.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INYsh9H1l-A9"
      },
      "source": [
        "# Update all client models to the federated average\n",
        "get_averaged_weights_and_update_main_model(model_dict, clients_to_be_trained)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ah8fiF96l-A9"
      },
      "source": [
        "# Compares the accuracy of the main model and the local model running on each node\n",
        "compare_local_and_merged_model_performance(clients_to_be_trained,clients_to_be_tested,'test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUjRg49Ql-A-"
      },
      "source": [
        "# Updating client models\n",
        "send_main_model_to_nodes_and_update_model_dict(main_model, model_dict, number_of_samples)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQ2Eu82a9Fcr"
      },
      "source": [
        "RESULT:\n",
        "```\n",
        "   Test data        Accuracy   Precision     Recall       F1\n",
        "0\tAll\t        0.810945\t0.827068\t0.880000\t0.852713\n",
        "1\tApparel\t    0.962963\t1.000000\t0.933333\t0.965517\n",
        "2\tCars\t       0.800000\t0.888889\t0.888889\t0.888889\n",
        "3\tElectronics\t0.862069\t0.944444\t0.850000\t0.894737\n",
        "4\tFood\t       0.538462\t0.875000\t0.583333\t0.700000\n",
        "5\tRetail\t     0.750000\t0.764706\t0.928571\t0.838710\n",
        "6\tServices\t   0.794118\t0.789474\t0.833333\t0.810811\n",
        "7\tSoftware\t   0.900000\t0.947368\t0.900000\t0.923077\n",
        "8\tTransport\t  0.880000\t0.875000\t0.777778\t0.823529\n",
        "9\tOther\t      0.846154\t0.800000\t1.000000\t0.888889\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5J91fLNHmHeS"
      },
      "source": [
        "###Experiment 2\n",
        "Train local domain models over some domains ( eg. 1, 2, 3 ), fedAvg it, then test local and main models across all other ( eg. 4,5,6 ) domain tweets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ReGi2DTL5Kj-"
      },
      "source": [
        "clients_to_be_trained=[5,6,7,8]\n",
        "clients_to_be_tested=[0,1,2,3,4]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwAi3XwpLjgt"
      },
      "source": [
        "# Models and optimizers functions in nodes are defined\n",
        "model_dict, optimizer_dict = create_model_optimizer_dict(number_of_samples)\n",
        "name_of_models=list(model_dict.keys())\n",
        "name_of_optimizers=list(optimizer_dict.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTcxK4ZeAmMh"
      },
      "source": [
        "# Updating client models\n",
        "send_main_model_to_nodes_and_update_model_dict(main_model, model_dict, number_of_samples)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulrFOMs2LuCJ"
      },
      "source": [
        "# Models in the nodes are trained\n",
        "start_train_end_node_process(clients_to_be_trained)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0M0oqWcTLw7"
      },
      "source": [
        "# # Or load all trained local models\n",
        "# model_dict, optimizer_dict = load_all_models(number_of_samples)\n",
        "# name_of_models=list(model_dict.keys())\n",
        "# name_of_optimizers=list(optimizer_dict.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ho26CEdhL1Ot"
      },
      "source": [
        "# Update all client models to the federated average\n",
        "get_averaged_weights_and_update_main_model(model_dict, clients_to_be_trained)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyvdK7jUL7CJ"
      },
      "source": [
        "# Compares the accuracy of the main model and the local model running on each node\n",
        "compare_local_and_merged_model_performance(clients_to_be_trained,clients_to_be_tested,'all')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WS6t_zkBL9g1"
      },
      "source": [
        "# Updating client models\n",
        "send_main_model_to_nodes_and_update_model_dict(main_model, model_dict, number_of_samples)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}